---
title: "HW 8"
author: "Matthew Litz"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    number_sections: true    
    toc: true
    toc_float: true
    theme: cosmo
    highlight: espresso    
# You can make the format personal - this will get you started:  
# https://bookdown.org/yihui/rmarkdown/html-document.html#appearance_and_style    
---

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 5.5,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=TRUE)      # show R messages

library(tidyverse)
library(caret)
library(ISLR)
library(tree)
library(randomForest)
library(xgboost)
```

<!--- Change font sizes (or other css modifications) --->
<style>
h1.title {
  font-size: 2.2em; /* Title font size */
}
h1 {
  font-size: 2em;   /* Header 1 font size */
}
h2 {
  font-size: 1.5em;
}
h3 { 
  font-size: 1.2em;
}
pre {
  font-size: 0.8em;  /* Code and R output font size */
}
</style>



**DS 6030 | Summer 2021 | University of Virginia **

*******************************************


# Question 8
In the lab, a classification tree was applied to the Carseats data set after converting Sales into a qualitative response variable. Now we will seek to predict Sales using regression trees and related approaches, treating the response as a quantitative variable.


(a) Split the data set into a training set and a test set.

```{r question_9a, echo=TRUE, warnings=FALSE, messages=FALSE}

carseats <- data.frame(Carseats)
attach(carseats)



#Create training and test splits
train.rows <- sample(rownames(carseats), dim(carseats)[1]*0.60)
carseats_train <- carseats[train.rows, ]
carseats_test <- carseats[setdiff(rownames(carseats), train.rows), ]
c(dim(carseats_train)[1], dim(carseats_test)[1])


```

(b) Fit a regression tree to the training set. Plot the tree, and interpret the results. What test MSE do you obtain?



```{r question_8b, echo=TRUE}
set.seed(1)

#base r
tree.carseats=tree(Sales~.,carseats_train)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)

#calculating test MSE
yhat=predict(tree.carseats,newdata=carseats_test)
mean((yhat-carseats_test$Sales)^2)


```

A test MSE of 5.17302 was obtained.

(c) Use cross-validation in order to determine the optimal level of tree complexity. Does pruning the tree improve the test MSE?


```{r question_8c, echo=TRUE}


cv.tree.carseats=cv.tree(tree.carseats)
plot(cv.tree.carseats$size,cv.tree.carseats$dev,type='b')
prune.carseats=prune.tree(tree.carseats,best=5)
plot(prune.carseats)
text(prune.carseats,pretty=0)

#calculating test MSE
yhat=predict(prune.carseats,newdata=carseats_test)
mean((yhat-carseats_test$Sales)^2)




```

The new test MSE is 4.620164 - a slight reduction in the test MSE was obtained through pruning.


(d) Use the bagging approach in order to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important.

```{r question_8d, echo=TRUE}

set.seed(123)
bag.carseats=randomForest(Sales~.,data=carseats_train,mtry=10,importance=TRUE)
bag.carseats

yhat.bag = predict(bag.carseats,newdata=carseats_test)
plot(yhat.bag, carseats_test$Sales)
abline(0,1)
mean((yhat-carseats_test$Sales)^2)

importance(bag.carseats)
varImpPlot(bag.carseats)


```
Bagging is performed using the randomForest function when all predictors (m=10) are specified.  An MSE of 2.690961 was obtained, almost half of the MSE obtained from cross-validation.  Price and ShelveLoc were identified as the variables with the most importance.



(e) Use random forests to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important. Describe the eï¬€ect of m, the number of variables considered at each split, on the error rate obtained.



```{r question_8e, echo=TRUE}

rf.carseats=randomForest(Sales~.,data=carseats_train,mtry=5,importance=TRUE)
rf.carseats
#test MSE
yhat.rf=predict(rf.carseats,newdata=carseats_test)
mean((yhat.rf-carseats_test$Sales)^2)

importance(rf.carseats)
varImpPlot(rf.carseats)



```

The MSE was significantly reduced with th implementation of random forests



# Question 11
11. This question uses the Caravan data set.

```{r question_11, warning=FALSE, message=FALSE}

caravan <- data.frame(Caravan)
attach(caravan)


```


(a) Create a training set consisting of the first 1,000 observations, and a test set consisting of the remaining observations.

```{r question_11a, warning=FALSE, message=FALSE}

#Create training and test splits
train.rows <- sample(rownames(caravan), dim(caravan)[1]*0.1718)
caravan_train <- caravan[train.rows, ]
caravan_test <- caravan[setdiff(rownames(caravan), train.rows), ]
c(dim(caravan_train)[1], dim(caravan_test)[1])


```


(b) Fit a boosting model to the training set with Purchase as the response and the other variables as predictors. Use 1,000 trees, and a shrinkage value of 0.01. Which predictors appear to be the most important?

```{r question_11b, echo=TRUE, warnings=FALSE, messages=FALSE}






```






(c) Use the boosting model to predict the response on the test data.  Predict that a person will make a purchase if the estimated probability of purchase is greater than 20 %. Form a confusion matrix. What fraction of the people predicted to make a purchase do in fact make one? How does this compare with the results obtained from applying KNN or logistic regression to this data set?


```{r question_11c, echo=TRUE, warnings=FALSE, messages=FALSE}







```



```

