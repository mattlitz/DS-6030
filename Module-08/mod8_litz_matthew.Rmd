---
title: "HW 8"
author: "Matthew Litz"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    number_sections: false    
    toc: true
    toc_float: true
    theme: cosmo
    highlight: espresso    
# You can make the format personal - this will get you started:  
# https://bookdown.org/yihui/rmarkdown/html-document.html#appearance_and_style    
---

<!--- Below are global settings for knitr. You can override any of them by adding the changes to individual chunks --->

```{r global_options, include=FALSE}
knitr::opts_chunk$set(error=TRUE,        # Keep compiling upon error
                      collapse=FALSE,    # collapse by default
                      echo=TRUE,         # echo code by default
                      comment = "#>",    # change comment character
                      fig.width = 5.5,     # set figure width
                      fig.align = "center",# set figure position
                      out.width = "49%", # set width of displayed images
                      warning=TRUE,      # show R warnings
                      message=TRUE)      # show R messages

library(tidyverse)
library(caret)
library(ISLR)
library(tree)
library(randomForest)
library(xgboost)
library(Matrix)
library(magrittr)
library(dplyr)
library(glmnet)
```

<!--- Change font sizes (or other css modifications) --->
<style>
h1.title {
  font-size: 2.2em; /* Title font size */
}
h1 {
  font-size: 2em;   /* Header 1 font size */
}
h2 {
  font-size: 1.5em;
}
h3 { 
  font-size: 1.2em;
}
pre {
  font-size: 0.8em;  /* Code and R output font size */
}
</style>



**DS 6030 | Summer 2021 | University of Virginia **

*******************************************


# Question 8
In the lab, a classification tree was applied to the Carseats data set after converting Sales into a qualitative response variable. Now we will seek to predict Sales using regression trees and related approaches, treating the response as a quantitative variable.


(a) Split the data set into a training set and a test set.

```{r question_9a, echo=TRUE, warnings=FALSE, messages=FALSE}

carseats <- data.frame(Carseats)
attach(carseats)



#Create training and test splits
train.rows <- sample(rownames(carseats), dim(carseats)[1]*0.60)
carseats_train <- carseats[train.rows, ]
carseats_test <- carseats[setdiff(rownames(carseats), train.rows), ]
c(dim(carseats_train)[1], dim(carseats_test)[1])


```

(b) Fit a regression tree to the training set. Plot the tree, and interpret the results. What test MSE do you obtain?



```{r question_8b, echo=TRUE}
set.seed(1)

#base r
tree.carseats=tree(Sales~.,carseats_train)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)

#calculating test MSE
yhat=predict(tree.carseats,newdata=carseats_test)
mean((yhat-carseats_test$Sales)^2)


```

The test MSE output is presented within the code.

(c) Use cross-validation in order to determine the optimal level of tree complexity. Does pruning the tree improve the test MSE?


```{r question_8c, echo=TRUE}


cv.tree.carseats=cv.tree(tree.carseats)
plot(cv.tree.carseats$size,cv.tree.carseats$dev,type='b')
prune.carseats=prune.tree(tree.carseats,best=5)
plot(prune.carseats)
text(prune.carseats,pretty=0)

#calculating test MSE
yhat=predict(prune.carseats,newdata=carseats_test)
mean((yhat-carseats_test$Sales)^2)




```

The new test MSE from pruning is a slight increase.


(d) Use the bagging approach in order to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important.

```{r question_8d, echo=TRUE}

set.seed(123)
bag.carseats=randomForest(Sales~.,data=carseats_train,mtry=10,importance=TRUE)
bag.carseats

yhat.bag = predict(bag.carseats,newdata=carseats_test)
plot(yhat.bag, carseats_test$Sales)
abline(0,1)
mean((yhat.bag-carseats_test$Sales)^2)

importance(bag.carseats)
varImpPlot(bag.carseats)


```
Bagging is performed using the randomForest function when all predictors (m=10) are specified.  An MSE was calculated that's almost half of the MSE obtained from cross-validation.  Price and ShelveLoc were identified as the variables with the most importance.



(e) Use random forests to analyze this data. What test MSE do you obtain? Use the importance() function to determine which variables are most important. Describe the eï¬€ect of m, the number of variables considered at each split, on the error rate obtained.



```{r question_8e, echo=TRUE}

rf.carseats=randomForest(Sales~.,data=carseats_train,mtry=3,importance=TRUE)
rf.carseats
#test MSE
yhat.rf=predict(rf.carseats,newdata=carseats_test)
mean((yhat.rf-carseats_test$Sales)^2)

importance(rf.carseats)
varImpPlot(rf.carseats)



```

Similiar to bagging, the MSE was significantly reduced with the implementation of random forests when compared to pruning only.  The importance function indicates that Price and ShelveLoc are the most important predictors.  Starting with m = p/3, the MSE reduces as we approach the bagging implementation of m equal to the total number of predictors (10).



# Question 11
11. This question uses the Caravan data set.

```{r question_11, warning=FALSE, message=FALSE}

caravan <- data.frame(Caravan)
attach(caravan)

```


(a) Create a training set consisting of the first 1,000 observations, and a test set consisting of the remaining observations.

```{r question_11a, warning=FALSE, message=FALSE}

set.seed(1234)
#Create training and test splits
train.rows <- sample(rownames(caravan), dim(caravan)[1]*0.1718)
caravan_train <- caravan[train.rows, ]
caravan_test <- caravan[setdiff(rownames(caravan), train.rows), ]
c(dim(caravan_train)[1], dim(caravan_test)[1])

```


(b) Fit a boosting model to the training set with Purchase as the response and the other variables as predictors. Use 1,000 trees, and a shrinkage value of 0.01. Which predictors appear to be the most important?

```{r question_11b, echo=FALSE, warnings=FALSE, messages=FALSE}

#train and test matrices
trainm <- sparse.model.matrix(Purchase ~.-1,data=caravan_train)
train_label <- caravan_train[,"Purchase"]
train_matrix <- xgb.DMatrix(data = as.matrix(trainm),label = train_label)

testm <- sparse.model.matrix(Purchase ~.-1,data=caravan_test)
test_label <- caravan_test[,"Purchase"]
test_matrix <- xgb.DMatrix(data = as.matrix(testm),label = test_label)

#Parameters
nc <- length(unique(train_label))
xgb_paramns <- list("objective" = "reg:squarederror",
                    #"eval_metric" = "mlogloss",
                    #"num_class" = nc,
                    "learning_rate" = 0.01, #shrinkage
                    "num_parallel_tree"=1000)

watchlist <- list(train = train_matrix, test = test_matrix)

#xgb model
bst_model <- xgb.train(params = xgb_paramns,
                       data=train_matrix,
                       nrounds = 100,
                       watchlist = watchlist)



```


```{r xgb}

bst_model
importance <- xgb.importance(feature_names = colnames(train_matrix), model = bst_model)
head(importance)
xgb.plot.importance(importance)

e <- data.frame(bst_model$evaluation_log)
plot(e$iter,e$train_rmse, col='blue') 
lines(e$iter,e$test_rmse,col='red')

```

PBRAND, MBERMIDD, MOPLLAG, and MOSTYPE are the top 4 features with Gain values greater than 0.08.  "Gain" measures the improvement in accuracy a feature adds to the branches it is on.


(c) Use the boosting model to predict the response on the test data.  Predict that a person will make a purchase if the estimated probability of purchase is greater than 20%. Form a confusion matrix. What fraction of the people predicted to make a purchase do in fact make one? How does this compare with the results obtained from applying KNN or logistic regression to this data set?

93.2% of the people predicted actually make a purchase.  These results are similar to 10-fold CV results for KNN (94%) and logistic regression (91.7%).
 

```{r question_11c, echo=TRUE, warnings=FALSE, messages=FALSE}

#xgb predictions
p <- predict(bst_model,newdata = test_matrix)
head(p)

##pred <- matrix(p, nrow = nc, ncol = length(p)/nc) %>%
  #t() %>% 
  #data.frame() %>%
  #mutate(label=test_label, max_prob=max.col(.,"last")-1)

level <- c('Y', 'N')
pred_label <- level[as.numeric(p>0.8)+1]


#pred_label <- as.factor(as.numeric(p>0.2))
#pred_label <- as.numeric(factor(p>0.8))
#pred_label <- ifelse(p > 0.8, 1, 0)

actual_label <- level[as.numeric(caravan_test$Purchase)+1]
table(pred_label,test_label)
#head(pred)

(4492)/(4492+290+3+37)

```

```{r knn, echo=TRUE, message=FALSE, warning=FALSE}

#formula used throughout
fmla = as.formula(Purchase~.)

#define X.test
X.test <- hardhat::mold(fmla, data=caravan_test)$predictors

trControl <- caret::trainControl(method="cv", number=10,
                                     savePredictions=TRUE,
                                     classProbs = TRUE,
                                     allowParallel=TRUE)

knnFit = caret::train(Purchase ~ ., data=caravan_train, 
                 method='knn',
                 preProcess = c("center", "scale"),
                 trControl=trControl)

knnFit

#predict values and establish levels
knn_pred <- predict(knnFit, X.test, type="raw")
levels(knn_pred) <- c('no','yes')

#cm_truth <- as.factor(test$BlueTarp)
#confusionMatrix(knn_pred, test_label)
table(knn_pred, test_label)
(4529+0)/(4529+293+0+0)

```




Logistic Regression Results


```{r log, echo=TRUE, message=FALSE, warning=FALSE}

#formula used throughout
fmla = as.formula(Purchase~.)

#define X.test
X.test <- hardhat::mold(fmla, data=caravan_test)$predictors


trControl <- caret::trainControl(method="cv", number=10,
                                     savePredictions=TRUE,
                                     classProbs = TRUE,
                                     allowParallel=TRUE)

logitFit = train(fmla, data=caravan_train,
                 method="glm",
                 family='binomial',  
                 trControl=trControl)

logitFit

#predict values and eastablish levels
logit_pred <- predict(logitFit, X.test, type="raw")
levels(logit_pred) <- c('no','yes')

table(logit_pred, test_label)
(4394+30)/(4394+263+30+135)

```






```

